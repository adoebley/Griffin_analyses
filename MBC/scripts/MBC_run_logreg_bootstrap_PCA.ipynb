{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('starting')\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# cmd = ['--in_file','../number_of_sites_analysis/merged_data/30000_reformatted.txt',\n",
    "#        '--name','30000',\n",
    "#         '--status_column','revisions_ER_status_binary',\n",
    "#       '--iterations','20',\n",
    "#       '--out_dir','tmp/tmp/',\n",
    "#       '--report_interval','50',\n",
    "#        '--fraction_variance','.8']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--in_file', help='/path/to/data_reformatted.txt', required=True)\n",
    "parser.add_argument('--name', help='name for outputs', required=True)\n",
    "parser.add_argument('--status_column', help='column containing the status', required=True)\n",
    "parser.add_argument('--iterations', help='number of iterations', required=True, type = int)\n",
    "parser.add_argument('--out_dir', help='output directory', required=True)\n",
    "parser.add_argument('--report_interval', help='how frequently to print progress', default = 50, type = int)\n",
    "parser.add_argument('--fraction_variance', help='what fraction of the variance should be explained by the PCs used in the model', type = float)\n",
    "\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create directory to export results\n",
    "if not os.path.exists(args.out_dir):\n",
    "    os.mkdir(args.out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(in_file):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    data = pd.read_csv(in_file, sep='\\t')\n",
    "    data = data.set_index('sample')\n",
    "\n",
    "    #get features and exclude all other columns\n",
    "    features = data.columns[(data.columns.str.startswith('central_cov')) | (data.columns.str.startswith('mean_cov')) | (data.columns.str.startswith('amplitude')) | (data.columns.str.startswith('Ulz'))]\n",
    "    print('Features',len(features))\n",
    "\n",
    "    data = data.sort_index()\n",
    "\n",
    "    print('Total samples:',len(data))\n",
    "\n",
    "    #scale data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data[features])\n",
    "    data[features] = scaler.transform(data[features])\n",
    "    data[features].mean()\n",
    "    data['status'] = data[args.status_column]\n",
    "    data['status'] = data['status'].replace('+',1).replace('-',0)\n",
    "    \n",
    "    return(data,features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstrapping\n",
    "def run_bootstrap_with_PCA(data,iterations,features,report_interval,hyperparameters):\n",
    "    import time\n",
    "    import sys\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from matplotlib import pyplot as plt\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    probabilities = pd.DataFrame(index=data.index)\n",
    "    c_vals = []\n",
    "    coefs = pd.DataFrame(index=features)\n",
    "    num_pcs = []\n",
    "    train_indexes = []\n",
    "    \n",
    "    # Loop for each iteration\n",
    "    for i in range(iterations):\n",
    "            \n",
    "        #bootstrap a training set with replacement\n",
    "        X_train = data.sample(len(data), replace = True, random_state = i+100)[features]\n",
    "        y_train = data.sample(len(data), replace = True, random_state = i+100)['status']\n",
    "        \n",
    "        #the test set is all samples that aren't seen in the training data\n",
    "        X_test = data[~(data.index.isin(X_train.index))][features]\n",
    "        y_test = data[~(data.index.isin(X_train.index))]['status']\n",
    "        \n",
    "        #print(len(X_train),len(X_train.index.unique()),len(X_test))\n",
    "        \n",
    "        #perform PCA on the training set\n",
    "        n_components = min(len(features), len(X_train))\n",
    "        pca = PCA(n_components=n_components, svd_solver='randomized', random_state = 100)\n",
    "        PCs = pca.fit_transform(X_train[features])\n",
    "        principal_components = pd.DataFrame(data = PCs, columns = ['PC_'+str(m) for m in np.arange(n_components)], index = X_train.index)\n",
    "        \n",
    "        #find the principle components that make up 80% of the varience\n",
    "        for j in range(len(pca.explained_variance_ratio_)):\n",
    "            current_sum = pca.explained_variance_ratio_[:j].sum()\n",
    "            if current_sum>=args.fraction_variance:\n",
    "                break\n",
    "        #print('number of components:',j)\n",
    "        pca_features = ['PC_'+str(m) for m in np.arange(0,j)]\n",
    "        \n",
    "        #apply to the test data\n",
    "        test_PCs = pca.transform(X_test[features])\n",
    "        test_principal_components = pd.DataFrame(data = test_PCs , columns = ['PC_'+str(m) for m in np.arange(n_components)], index = X_test.index)\n",
    "        \n",
    "        X_train = principal_components[pca_features]\n",
    "        X_test = test_principal_components[pca_features]\n",
    "        \n",
    "        #10 fold cross validation on the training set\n",
    "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = i+100) \n",
    "\n",
    "        model = LogisticRegression(class_weight='balanced', max_iter=500, solver = 'liblinear')\n",
    "        search = GridSearchCV(estimator=model, param_grid=hyperparameters, cv=cv, n_jobs = 1)\n",
    "        search.fit(X_train, y_train)\n",
    "        best_C = search.best_params_['C']\n",
    "\n",
    "        ##train a new model on the full training dataset (is this the same as refit...?)\n",
    "        model = LogisticRegression(class_weight='balanced', max_iter=500, C=best_C, solver = 'liblinear')\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        #predict the test data\n",
    "        pred = model.predict(X_test)\n",
    "        prob = model.predict_proba(X_test)\n",
    "\n",
    "        #save results\n",
    "        probabilities[i] = pd.Series(prob[:,1], index = X_test.index)\n",
    "        c_vals.append(best_C)\n",
    "        coefs[i] = pd.Series(model.coef_[0], index = pca_features)\n",
    "        num_pcs.append(j)\n",
    "     \n",
    "        train_indexes.append(list(X_train.index))\n",
    "        \n",
    "        if i%report_interval==0:\n",
    "            print('iteration:',i, ', time (sec):',np.round(time.time()-start_time,2),'num_pcs:',j)\n",
    "        if i%20==0:\n",
    "            #prevent dfs from becoming too fragmented\n",
    "            probabilities = probabilities.copy()\n",
    "            coefs = coefs.copy()   \n",
    "            sys.stdout.flush()\n",
    "\n",
    "    probabilities = probabilities.merge(data[['status']], left_index=True, right_index=True)\n",
    "\n",
    "    return(probabilities,c_vals,coefs,num_pcs,train_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_AUC(probabilities,data,iterations):\n",
    "    #get AUC and accuracy for each bootstrap\n",
    "    from sklearn.metrics import roc_curve,auc\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    AUCs = pd.DataFrame()\n",
    "    accuracies = pd.DataFrame()\n",
    "\n",
    "    probabilities = probabilities.merge(data[['first_passing_sample','tumor_fraction']], left_index=True, right_index=True)\n",
    "    probabilities = probabilities[probabilities['first_passing_sample']==1]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        current_accuracy_dict = {}\n",
    "        current_AUC_dict = {}\n",
    "        \n",
    "        current = probabilities[~(probabilities[i].isnull())][['status','tumor_fraction',i]].copy()\n",
    "\n",
    "        current['accuracy'] = np.where(np.round(current[i])==current['status'],1,0)\n",
    "        \n",
    "        low_tfx = current[(current['tumor_fraction']<0.1)].copy()\n",
    "        high_tfx = current[(current['tumor_fraction']>=0.1)].copy()\n",
    "\n",
    "        for group,df in zip(['overall','high_tfx','low_tfx'],[current,high_tfx,low_tfx]):\n",
    "            fpr,tpr,_ = roc_curve(df['status'],df[i])\n",
    "\n",
    "            AUC = auc(fpr,tpr)\n",
    "            current_AUC_dict[group] = AUC\n",
    "\n",
    "            accuracy = sum(np.round(df[i])==df['status'])/len(df)\n",
    "            current_accuracy_dict[group] = accuracy\n",
    "            \n",
    "        accuracies = accuracies.append(pd.Series(current_accuracy_dict), ignore_index=True)\n",
    "        AUCs = AUCs.append(pd.Series(current_AUC_dict), ignore_index=True)\n",
    "        \n",
    "\n",
    "    AUC_CIs = pd.DataFrame([AUCs.median(), AUCs.quantile(.025), AUCs.quantile(.975)]).T\n",
    "    AUC_CIs = AUC_CIs.rename(columns = {'Unnamed 0':'median'})    \n",
    "\n",
    "    accuracy_CIs = pd.DataFrame([accuracies.median(), accuracies.quantile(.025), accuracies.quantile(.975)]).T\n",
    "    accuracy_CIs = accuracy_CIs.rename(columns = {'Unnamed 0':'median'})    \n",
    "\n",
    "    return(accuracies,accuracy_CIs,AUCs,AUC_CIs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('analysis name',args.name)\n",
    "print('importing data')\n",
    "data,features  = import_data(args.in_file)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('status')\n",
    "print(data['status'].value_counts())\n",
    "    \n",
    "print('tfx:')\n",
    "low_tfx = data[(data['tumor_fraction']>=0.05) & (data['tumor_fraction']<0.1)]\n",
    "high_tfx = data[(data['tumor_fraction']>=0.1)]\n",
    "\n",
    "print('low tfx:',len(low_tfx))\n",
    "print('high tfx:',len(high_tfx))\n",
    "\n",
    "del(high_tfx,low_tfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('running '+str(args.iterations)+' logreg bootstrap iterations')\n",
    "hyperparameters = {'C': [0.0001, 0.001,0.01,0.1,1,10,100,1000]}\n",
    "\n",
    "probabilities,c_vals,coefs,num_pcs,train_indexes = run_bootstrap_with_PCA(data,args.iterations,features,args.report_interval,hyperparameters)    \n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Getting AUC')\n",
    "sys.stdout.flush()\n",
    "accuracies,accuracy_CIs,AUCs,AUC_CIs = get_accuracy_AUC(probabilities,data,args.iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities.to_csv(args.out_dir+'/'+args.name+'.probabilities.txt', sep='\\t', float_format='%.5f')\n",
    "pd.Series(c_vals).to_csv(args.out_dir+'/'+args.name+'.c_values.txt', sep='\\t', header = False, index=False)\n",
    "coefs.to_csv(args.out_dir+'/'+args.name+'.coefs.txt', sep='\\t', float_format='%.5f')\n",
    "pd.Series(num_pcs).to_csv(args.out_dir+'/'+args.name+'.num_pcs.'+str(args.fraction_variance)+'.txt', sep='\\t', header = False, index=False)\n",
    "pd.Series(train_indexes).to_csv(args.out_dir+'/'+args.name+'.train_indexes.txt', sep='\\t', header = False, index=False)\n",
    "\n",
    "accuracies.to_csv(args.out_dir+'/'+args.name+'.accuracy.txt', sep='\\t', index = False, float_format='%.5f')\n",
    "accuracy_CIs.to_csv(args.out_dir+'/'+args.name+'.accuracy_CI.txt', sep='\\t', float_format = '%.5f')\n",
    "AUCs.to_csv(args.out_dir+'/'+args.name+'.AUC.txt', sep='\\t', index = False, float_format='%.5f')\n",
    "AUC_CIs.to_csv(args.out_dir+'/'+args.name+'.AUC_CI.txt', sep='\\t', float_format = '%.5f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(np.log10(hyperparameters['C']))+[np.log10(max(hyperparameters['C'])*10)]\n",
    "plt.hist(np.log10(c_vals),bins = bins, label=hyperparameters['C'],  align = 'left', rwidth = .8);\n",
    "plt.xlabel('log10 C value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig(args.out_dir+'/'+args.name+'.cvals.pdf')   \n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(num_pcs, range = (min(num_pcs),max(num_pcs)+1), bins = max(num_pcs) - min(num_pcs)+1, align = 'left', rwidth=.8)\n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('number of pcs')\n",
    "plt.savefig(args.out_dir+'/'+args.name+'.pcs.'+str(args.fraction_variance)+'.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUCs')\n",
    "print(AUC_CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracies')\n",
    "print(accuracy_CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
