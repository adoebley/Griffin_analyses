{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "import pybedtools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script calculates the frequency of each GC content for fragments that overlap the non-blacklisted areas\n",
    "#This is performed for each fragment size in the range specified\n",
    "#this only needs to be performed once for each filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# #arguments for testing \n",
    "# mappable_regions_path = '/fh/fast/ha_g/user/adoebley/projects/griffin_revisions_1/genome/k100_minus_exclusion_lists.mappable_regions.hg38.bed'\n",
    "\n",
    "# ref_seq_path = '/fh/fast/ha_g/grp/reference/GRCh38/GRCh38.fa'\n",
    "# chrom_sizes_path = '/fh/fast/ha_g/grp/reference/GRCh38/hg38.standard.chrom.sizes'\n",
    "# out_dir = 'tmp'\n",
    "\n",
    "# fragment_length = 165 #fragment length\n",
    "# read_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--mappable_regions_path', help='highly mappable regions to be used in GC correction, bed or bedGraph format', required=True)\n",
    "parser.add_argument('--ref_seq',help='reference sequence (fasta format)',required=True)\n",
    "parser.add_argument('--chrom_sizes',help='path to chromosome sizes for the reference seq',required=True)\n",
    "parser.add_argument('--out_dir',help='folder for results',required=True)\n",
    "parser.add_argument('--fragment_length',help='length of fragment (in bp) for which GC will be calculated',type=int, required=True)\n",
    "parser.add_argument('--read_length',help='length of read (in bp)',type=int, required=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "mappable_regions_path=args.mappable_regions_path\n",
    "ref_seq_path = args.ref_seq\n",
    "chrom_sizes_path = args.chrom_sizes\n",
    "out_dir = args.out_dir\n",
    "fragment_length = args.fragment_length\n",
    "read_length = args.read_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappable_name = mappable_regions_path.rsplit('/',1)[1].rsplit('.',1)[0]\n",
    "out_file = out_dir+'/'+mappable_name+'.'+str(fragment_length)+'bp.GC_frequency.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep autosomes only\n",
    "chroms = ['chr'+str(m) for m in range(1,23)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_length>fragment_length:\n",
    "    read_length = fragment_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mappable_regions_path: /fh/fast/ha_g/user/adoebley/projects/nucleosome_profiling_griffin/add_mappability_1/genome_info/k100_exclusion_lists.mappable_regions.bed\n",
      "out_file: tmp/k100_exclusion_lists.mappable_regions.165bp.GC_frequency.txt\n",
      "fragment_length: 165\n",
      "read_length: 100\n"
     ]
    }
   ],
   "source": [
    "print('mappable_regions_path:',mappable_regions_path)\n",
    "print('out_file:',out_file)\n",
    "print('fragment_length:',fragment_length)\n",
    "print('read_length:',read_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chroms: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22']\n",
      "number_of_intervals: 467958\n"
     ]
    }
   ],
   "source": [
    "#import filter\n",
    "mappable_intervals = pd.read_csv(mappable_regions_path, sep='\\t', header=None)\n",
    "\n",
    "mappable_intervals = mappable_intervals[mappable_intervals[0].isin(chroms)]\n",
    "\n",
    "print('chroms:', chroms)\n",
    "print('number_of_intervals:',len(mappable_intervals))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0      1      2\n",
      "0  chr1  10107  10439\n",
      "1  chr1  10581  10622\n",
      "2  chr1  13325  13326\n",
      "3  chr1  13978  13979\n",
      "4  chr1  15242  15273\n"
     ]
    }
   ],
   "source": [
    "print(mappable_intervals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get chrom sizes info\n",
    "chrom_sizes = pd.read_csv(chrom_sizes_path, sep='\\t', header=None)\n",
    "\n",
    "#also keep as a dict\n",
    "chrom_size_dict = chrom_sizes.set_index(0).to_dict()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the ref_seq\n",
    "ref_seq=pysam.FastaFile(ref_seq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval 0 : chr1 10108 10438 seconds: 0.0\n",
      "interval 5000 : chr1 27829386 27829385 seconds: 19.0\n",
      "interval 10000 : chr1 67436203 67438735 seconds: 48.0\n",
      "interval 15000 : chr1 99026501 99042644 seconds: 71.0\n",
      "interval 20000 : chr1 120980208 120980211 seconds: 87.0\n",
      "interval 25000 : chr1 146622714 146622713 seconds: 90.0\n",
      "interval 30000 : chr1 152615293 152615495 seconds: 95.0\n",
      "interval 35000 : chr1 184132198 184132245 seconds: 118.0\n",
      "interval 40000 : chr1 221974800 221975255 seconds: 145.0\n",
      "interval 45000 : chr10 4113476 4117387 seconds: 168.0\n",
      "interval 50000 : chr10 42531634 42534505 seconds: 194.0\n",
      "interval 55000 : chr10 50193993 50193992 seconds: 200.0\n",
      "interval 60000 : chr10 80885403 80885487 seconds: 223.0\n",
      "interval 65000 : chr10 114741514 114752767 seconds: 248.0\n",
      "interval 70000 : chr11 14664621 14664671 seconds: 272.0\n",
      "interval 75000 : chr11 49041185 49041242 seconds: 298.0\n",
      "interval 80000 : chr11 71679800 71679799 seconds: 312.0\n",
      "interval 85000 : chr11 94241278 94248951 seconds: 329.0\n",
      "interval 90000 : chr12 5665364 5665543 seconds: 362.0\n",
      "interval 95000 : chr12 32473252 32473443 seconds: 381.0\n",
      "interval 100000 : chr12 63435767 63435766 seconds: 402.0\n",
      "interval 105000 : chr12 101511808 101513178 seconds: 429.0\n",
      "interval 110000 : chr13 21280171 21280170 seconds: 454.0\n",
      "interval 115000 : chr13 54737086 54737150 seconds: 479.0\n",
      "interval 120000 : chr13 104456392 104467686 seconds: 515.0\n",
      "interval 125000 : chr14 29333622 29333715 seconds: 529.0\n",
      "interval 130000 : chr14 63548538 63561159 seconds: 554.0\n",
      "interval 135000 : chr15 38583430 38583453 seconds: 590.0\n",
      "interval 140000 : chr15 77979637 77979792 seconds: 618.0\n",
      "interval 145000 : chr16 9677154 9677153 seconds: 642.0\n",
      "interval 150000 : chr16 31978161 31978170 seconds: 655.0\n",
      "interval 155000 : chr16 54158260 54158382 seconds: 664.0\n",
      "interval 160000 : chr16 87935712 87940799 seconds: 688.0\n",
      "interval 165000 : chr17 18608459 18608622 seconds: 703.0\n",
      "interval 170000 : chr17 31018484 31019334 seconds: 710.0\n",
      "interval 175000 : chr17 64841516 64841945 seconds: 731.0\n",
      "interval 180000 : chr18 14485814 14485849 seconds: 755.0\n",
      "interval 185000 : chr18 49493809 49508385 seconds: 776.0\n",
      "interval 190000 : chr19 12905593 12908435 seconds: 807.0\n",
      "interval 195000 : chr19 43275993 43276416 seconds: 826.0\n",
      "interval 200000 : chr2 21493043 21493209 seconds: 852.0\n",
      "interval 205000 : chr2 66908826 66908838 seconds: 885.0\n",
      "interval 210000 : chr2 87872330 87872473 seconds: 901.0\n",
      "interval 215000 : chr2 96014440 96014439 seconds: 904.0\n",
      "interval 220000 : chr2 111577345 111577543 seconds: 916.0\n",
      "interval 225000 : chr2 131228887 131228886 seconds: 931.0\n",
      "interval 230000 : chr2 157708339 157709658 seconds: 950.0\n",
      "interval 235000 : chr2 197566166 197581749 seconds: 980.0\n",
      "interval 240000 : chr20 2056282 2056324 seconds: 1012.0\n",
      "interval 245000 : chr20 30268194 30268373 seconds: 1031.0\n",
      "interval 250000 : chr21 6098962 6098994 seconds: 1057.0\n",
      "interval 255000 : chr21 13231521 13232299 seconds: 1059.0\n",
      "interval 260000 : chr21 44131076 44131075 seconds: 1082.0\n",
      "interval 265000 : chr22 15881284 15881325 seconds: 1086.0\n",
      "interval 270000 : chr22 29198837 29210370 seconds: 1096.0\n",
      "interval 275000 : chr3 20867648 20867660 seconds: 1127.0\n",
      "interval 280000 : chr3 58936553 58936552 seconds: 1155.0\n",
      "interval 285000 : chr3 99203004 99208676 seconds: 1182.0\n",
      "interval 290000 : chr3 134587353 134656894 seconds: 1208.0\n",
      "interval 295000 : chr3 171638209 171645699 seconds: 1235.0\n",
      "interval 300000 : chr4 8632181 8632180 seconds: 1261.0\n",
      "interval 305000 : chr4 45815924 45816654 seconds: 1289.0\n",
      "interval 310000 : chr4 75216946 75216950 seconds: 1308.0\n",
      "interval 315000 : chr4 106405150 106405472 seconds: 1332.0\n",
      "interval 320000 : chr4 131849165 131849217 seconds: 1352.0\n",
      "interval 325000 : chr4 163717845 163718205 seconds: 1376.0\n",
      "interval 330000 : chr5 11296695 11303796 seconds: 1403.0\n",
      "interval 335000 : chr5 34394385 34394384 seconds: 1420.0\n",
      "interval 340000 : chr5 66108161 66109203 seconds: 1441.0\n",
      "interval 345000 : chr5 100092646 100092716 seconds: 1465.0\n",
      "interval 350000 : chr5 133857308 133857366 seconds: 1489.0\n",
      "interval 355000 : chr5 176061405 176061548 seconds: 1520.0\n",
      "interval 360000 : chr6 26908564 26908564 seconds: 1543.0\n",
      "interval 365000 : chr6 57973052 57973152 seconds: 1563.0\n",
      "interval 370000 : chr6 74106663 74119790 seconds: 1573.0\n",
      "interval 375000 : chr6 103656252 103663352 seconds: 1595.0\n",
      "interval 380000 : chr6 145106168 145106864 seconds: 1625.0\n",
      "interval 385000 : chr7 8737614 8737801 seconds: 1649.0\n",
      "interval 390000 : chr7 39435639 39437236 seconds: 1672.0\n",
      "interval 395000 : chr7 57866902 57866982 seconds: 1687.0\n",
      "interval 400000 : chr7 72944822 72944883 seconds: 1695.0\n",
      "interval 405000 : chr7 90113005 90113004 seconds: 1708.0\n",
      "interval 410000 : chr7 116413850 116413905 seconds: 1728.0\n",
      "interval 415000 : chr7 150223347 150223347 seconds: 1752.0\n"
     ]
    }
   ],
   "source": [
    "#count the GC content of all fragments where the forward read overlaps the specified regions\n",
    "start_time = time.time()\n",
    "print('Calculating forward read frequency')\n",
    "\n",
    "#create the GC frequencies dict\n",
    "fw_GC_dict = {}\n",
    "for num_GC in range(0,fragment_length+1):\n",
    "    fw_GC_dict[num_GC]=0\n",
    "    \n",
    "for i in range(len(mappable_intervals)):\n",
    "    chrom = mappable_intervals.iloc[i][0]\n",
    "    start = mappable_intervals.iloc[i][1]+1\n",
    "    end = mappable_intervals.iloc[i][2]-1\n",
    "    if i%5000==0:\n",
    "        print('interval',i,':',chrom,start,end,'seconds:',np.round(time.time()-start_time))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    #count up all possible fw reads that overlap the interval\n",
    "    #adjust the start and end so it includes all possible fragment that overlap the interval \n",
    "    adjusted_start = start-read_length\n",
    "    adjusted_end = end+fragment_length\n",
    "    \n",
    "    if adjusted_start<0:\n",
    "        adjusted_start = 0\n",
    "    if adjusted_end>chrom_size_dict[chrom]:\n",
    "        adjusted_end = chrom_sizes_dict[chrom]\n",
    "        print(chrom,chrom_sizes_dict[chrom],'modifying_end_to_end_of_chromosome')\n",
    "\n",
    "    #print('fetch start',adjusted_start-start)\n",
    "    #print('fetch end',adjusted_end-end)\n",
    "    \n",
    "    fetched = ref_seq.fetch(chrom,adjusted_start,adjusted_end)\n",
    "    fetched = fetched.replace('g','G').replace('c','C').replace('a','A').replace('t','T').replace('n','N')\n",
    "    fetched = np.array(list(fetched.replace('G','1').replace('C','1').replace('A','0').replace('T','0').replace('N','2')),dtype=float)\n",
    "\n",
    "    #swap the 2 for a random 1 or 0 #there has to be a better way to do this but I can't figure it out\n",
    "    #the 0 or 1 is required because the sliding window sum algorithm only does integers\n",
    "    #unknown nucleotides should be quite rare if the filter is done correctly\n",
    "    rng = np.random.default_rng(start)\n",
    "    fetched[fetched==2] = rng.integers(2, size=len(fetched[fetched==2])) #random integer in range(2) (i.e. 0 or 1)\n",
    "\n",
    "    n=len(fetched)\n",
    "\n",
    "    window_sum = int(sum(fetched[:fragment_length]))\n",
    "    #print(k,len(fetched[:k]),window_sum)\n",
    "\n",
    "    fw_GC_dict[window_sum]+=1\n",
    "    for i in range(n-fragment_length):\n",
    "        window_sum = int(window_sum - fetched[i] + fetched[i+fragment_length])\n",
    "        fw_GC_dict[window_sum]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the GC content of all fragments where the reverse read overlaps the specified regions\n",
    "print('Calculating reverse read frequency')\n",
    "\n",
    "#create the GC frequencies dict\n",
    "rv_GC_dict = {}\n",
    "for num_GC in range(0,fragment_length+1):\n",
    "    rv_GC_dict[num_GC]=0\n",
    "    \n",
    "for i in range(len(mappable_intervals)):\n",
    "    chrom = mappable_intervals.iloc[i][0]\n",
    "    start = mappable_intervals.iloc[i][1]+1 #skip the first and last positions because these reads aren't fetched by pysam\n",
    "    end = mappable_intervals.iloc[i][2]-1\n",
    "    if i%5000==0:\n",
    "        print('interval',i,':',chrom,start,end,'seconds:',np.round(time.time()-start_time))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    #count up all possible rv reads that overlap the interval\n",
    "    #adjust the start and end so it includes all possible fragment that overlap the interval \n",
    "    adjusted_start = start-fragment_length\n",
    "    adjusted_end = end+read_length\n",
    "    \n",
    "    if adjusted_start<0:\n",
    "        adjusted_start = 0\n",
    "    if adjusted_end>chrom_size_dict[chrom]:\n",
    "        adjusted_end = chrom_sizes_dict[chrom]\n",
    "        print(chrom,chrom_sizes_dict[chrom],'modifying_end_to_end_of_chromosome')\n",
    "\n",
    "    #print('fetch start',adjusted_start-start)\n",
    "    #print('fetch end',adjusted_end-end)\n",
    "        \n",
    "    fetched = ref_seq.fetch(chrom,adjusted_start,adjusted_end)\n",
    "    fetched = fetched.replace('g','G').replace('c','C').replace('a','A').replace('t','T').replace('n','N')\n",
    "    fetched = np.array(list(fetched.replace('G','1').replace('C','1').replace('A','0').replace('T','0').replace('N','2')),dtype=float)\n",
    "\n",
    "    #swap the 2 for a random 1 or 0 #there has to be a better way to do this but I can't figure it out\n",
    "    #the 0 or 1 is required because the sliding window sum algorithm only does integers\n",
    "    #unknown nucleotides should be quite rare if the filter is done correctly\n",
    "    rng = np.random.default_rng(start)\n",
    "    fetched[fetched==2] = rng.integers(2, size=len(fetched[fetched==2])) #random integer in range(2) (i.e. 0 or 1)\n",
    "\n",
    "    n=len(fetched)\n",
    "\n",
    "    window_sum = int(sum(fetched[:fragment_length]))\n",
    "    #print(k,len(fetched[:k]),window_sum)\n",
    "\n",
    "    rv_GC_dict[window_sum]+=1\n",
    "    for i in range(n-fragment_length):\n",
    "        window_sum = int(window_sum - fetched[i] + fetched[i+fragment_length])\n",
    "        rv_GC_dict[window_sum]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to df and export\n",
    "GC_df = pd.DataFrame()\n",
    "#save GC dict\n",
    "current = (pd.Series(rv_GC_dict)+pd.Series(fw_GC_dict)).reset_index()\n",
    "current = current.rename(columns={'index':'num_GC',0:'number_of_fragments'})\n",
    "current['length']=fragment_length\n",
    "current = current[['length','num_GC','number_of_fragments']]\n",
    "GC_df = GC_df.append(current, ignore_index=True)\n",
    "GC_df.to_csv(out_file,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
