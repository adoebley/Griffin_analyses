{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import os\n",
    "#import pybedtools #not used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# bam_file_name = 'MBC_1041_1_ULP'\n",
    "# mappable_name = 'k100_minus_exclusion_lists.mappable_regions.hg38'\n",
    "# genome_GC_frequency = '/fh/fast/ha_g/user/adoebley/projects/griffin_revisions_1/Griffin/snakemakes/griffin_genome_GC_frequency/results'\n",
    "# out_dir = 'tmp'\n",
    "# size_range = [15,500]\n",
    "# fragment_length = 165\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--bam_file_name', help='sample name (does not need to match actual file name)', required=True)\n",
    "\n",
    "parser.add_argument('--mappable_name', help='name of mappable regions file (with .bed removed)', required=True)\n",
    "\n",
    "parser.add_argument('--genome_GC_frequency',help='folder containing GC counts in the reference sequence (made by generate_reference_files.snakemake)',required=True)\n",
    "\n",
    "parser.add_argument('--out_dir',help='folder for GC bias results',required=True)\n",
    "\n",
    "parser.add_argument('--size_range',help='range of read sizes to be included',nargs=2, type=int, required=True)\n",
    "parser.add_argument('--fragment_length',help='most common fragment size',type=int, required=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "bam_file_name = args.bam_file_name\n",
    "mappable_name=args.mappable_name\n",
    "genome_GC_frequency = args.genome_GC_frequency\n",
    "out_dir = args.out_dir\n",
    "size_range = args.size_range\n",
    "fragment_length = args.fragment_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('arguments provided:')\n",
    "\n",
    "print('\\tbam_file_name = \"'+bam_file_name+'\"')\n",
    "print('\\tmappable_name = \"'+mappable_name+'\"')\n",
    "\n",
    "print('\\tgenome_GC_frequency = \"'+genome_GC_frequency+'\"')\n",
    "out_dir = out_dir.rstrip('/')\n",
    "print('\\tout_dir = \"'+out_dir+'\"')\n",
    "\n",
    "print('\\tsize_range = '+str(size_range))\n",
    "print('\\tfragment_length = '+str(fragment_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now I'm going to keep the smoothing bin size as a set variable\n",
    "GC_smoothing_step = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input is the out_file from the previous step\n",
    "in_file = out_dir +'/GC_counts/'+ bam_file_name+'.GC_counts.txt'\n",
    "print('in_file:',in_file)\n",
    "\n",
    "#output is smoothed version\n",
    "smoothed_out_file = out_dir +'/GC_bias/'+ bam_file_name+'.GC_bias.txt'\n",
    "\n",
    "#plot files\n",
    "plot_file1 = out_dir +'/GC_plots/'+ bam_file_name+'.GC_bias.pdf'\n",
    "\n",
    "print('out_file:',smoothed_out_file)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create output folders if needed\n",
    "if not os.path.exists(out_dir +'/GC_plots/'):\n",
    "    os.mkdir(out_dir +'/GC_plots/')\n",
    "if not os.path.exists(out_dir +'/GC_bias/'):\n",
    "    os.mkdir(out_dir +'/GC_bias/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the GC info from the genome\n",
    "current_path = genome_GC_frequency+'/'+mappable_name+'.'+str(fragment_length)+'bp.GC_frequency.txt'\n",
    "GC_freq = pd.read_csv(current_path,sep='\\t')\n",
    "    \n",
    "GC_freq['GC_content']=GC_freq['num_GC']/GC_freq['length']\n",
    "GC_freq = GC_freq.sort_values(by=['GC_content','length']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import GC counts from the sample\n",
    "GC_df = pd.read_csv(in_file, sep='\\t')\n",
    "\n",
    "GC_df['GC_content']=GC_df['num_GC']/GC_df['length']\n",
    "GC_df = GC_df.sort_values(by=['GC_content','length']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the GC_bias\n",
    "\n",
    "new_df = GC_df[GC_df['length']==fragment_length].copy().reset_index(drop=True)\n",
    "current_freq = GC_freq[GC_freq['length']==fragment_length].copy().reset_index(drop=True)\n",
    "\n",
    "#save the frequency of each GC content in the genome\n",
    "new_df['number_of_positions']=current_freq['number_of_fragments']\n",
    "\n",
    "#calculate the GC bias\n",
    "current_bias = new_df['number_of_fragments']/new_df['number_of_positions']    \n",
    "new_df['GC_bias'] = current_bias\n",
    "\n",
    "#normalize to a mean of 1 for each fragment length(compute GC bias does this same thing)\n",
    "new_df['GC_bias'] = new_df['GC_bias']/np.nanmean(new_df['GC_bias'])\n",
    "\n",
    "#print(length,len(new_df['GC_bias']),np.nanmean(new_df['GC_bias']))\n",
    "    \n",
    "new_df = new_df.sort_values(by=['GC_content','length']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_smoothing(current,fraction):\n",
    "    bin_size=int(len(current)*fraction)\n",
    "    #if bin_size<10:\n",
    "        #bin_size=10\n",
    "    medians = []\n",
    "\n",
    "    for i in range(len(current)):\n",
    "        start = int(i-bin_size/2)\n",
    "        end = int(i+bin_size/2)\n",
    "        #if the bin starts before the beginning, just take the first bin\n",
    "        if start<0:\n",
    "            start=0\n",
    "            end=bin_size\n",
    "        #if the bin extends beyond the end, take the last bin\n",
    "        if end>=len(current):\n",
    "            start=len(current)-bin_size\n",
    "            end=len(current)\n",
    "        current_median = np.nanmedian(current['GC_bias'].iloc[start:end])\n",
    "        medians.append(current_median)\n",
    "    return(medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#perform smoothing\n",
    "fit = median_smoothing(new_df,.05)  \n",
    "new_df['smoothed_GC_bias']=fit\n",
    "    \n",
    "    \n",
    "#get rid of values for GC contents that are never observed\n",
    "new_df['smoothed_GC_bias'] = np.where(new_df['number_of_positions']==0,np.nan,new_df['smoothed_GC_bias'])\n",
    "    \n",
    "#normalize to a mean of 1\n",
    "new_df['smoothed_GC_bias'] = new_df['smoothed_GC_bias']/np.nanmean(new_df['smoothed_GC_bias'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export results\n",
    "new_df.to_csv(smoothed_out_file,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize = (10,4))\n",
    "\n",
    "axes[0].plot(new_df['GC_content'], new_df['number_of_positions']/np.nanmean(new_df['number_of_positions']),label = 'number_of_positions')\n",
    "axes[0].plot(new_df['GC_content'], new_df['number_of_fragments']/np.nanmean(new_df['number_of_fragments']),label = 'number_of_fragments')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_xlabel('GC_content')\n",
    "\n",
    "axes[0].legend(bbox_to_anchor = [1,1], loc = 'upper left')\n",
    "\n",
    "axes[1].plot(new_df['GC_content'], new_df['GC_bias'],label = 'GC_bias')\n",
    "axes[1].plot(new_df['GC_content'], new_df['smoothed_GC_bias'],label = 'smoothed_GC_bias')\n",
    "axes[1].set_ylabel('GC_bias')\n",
    "axes[1].set_xlabel('GC_content')\n",
    "axes[1].legend(bbox_to_anchor = [1,1], loc = 'upper left')\n",
    "\n",
    "fig.suptitle(bam_file_name+'\\n'+mappable_name + '\\n' + str(fragment_length)+'bp')\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file1)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
