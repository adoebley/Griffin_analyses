{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "import pybedtools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script calculates the frequency of each GC content for fragments that overlap the non-blacklisted areas\n",
    "#This is performed for each fragment size in the range specified\n",
    "#this only needs to be performed once for each filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# #arguments for testing \n",
    "# mappable_regions_path = '/fh/fast/ha_g/user/adoebley/projects/griffin_revisions_1/genome/k100_minus_exclusion_lists.mappable_regions.hg38.bed'\n",
    "\n",
    "# # ref_seq_path = '/fh/fast/ha_g/grp/reference/GRCh38/GRCh38.fa'\n",
    "# ref_seq_path = '../../../mods_for_WDL/ref/Homo_sapiens_assembly38.fasta'#test for Amy\n",
    "# chrom_sizes_path = '/fh/fast/ha_g/grp/reference/GRCh38/hg38.standard.chrom.sizes'\n",
    "# out_dir = 'tmp'\n",
    "\n",
    "# fragment_length = 165 #fragment length\n",
    "# read_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--mappable_regions_path', help='highly mappable regions to be used in GC correction, bed or bedGraph format', required=True)\n",
    "parser.add_argument('--ref_seq',help='reference sequence (fasta format)',required=True)\n",
    "parser.add_argument('--chrom_sizes',help='path to chromosome sizes for the reference seq',required=True)\n",
    "parser.add_argument('--out_dir',help='folder for results',required=True)\n",
    "parser.add_argument('--fragment_length',help='length of fragment (in bp) for which GC will be calculated',type=int, required=True)\n",
    "parser.add_argument('--read_length',help='length of read (in bp)',type=int, required=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "mappable_regions_path=args.mappable_regions_path\n",
    "ref_seq_path = args.ref_seq\n",
    "chrom_sizes_path = args.chrom_sizes\n",
    "out_dir = args.out_dir\n",
    "fragment_length = args.fragment_length\n",
    "read_length = args.read_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappable_name = mappable_regions_path.rsplit('/',1)[1].rsplit('.',1)[0]\n",
    "out_file = out_dir+'/'+mappable_name+'.'+str(fragment_length)+'bp.GC_frequency.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep autosomes only\n",
    "chroms = ['chr'+str(m) for m in range(1,23)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_length>fragment_length:\n",
    "    read_length = fragment_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mappable_regions_path:',mappable_regions_path)\n",
    "print('out_file:',out_file)\n",
    "print('fragment_length:',fragment_length)\n",
    "print('read_length:',read_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import filter\n",
    "mappable_intervals = pd.read_csv(mappable_regions_path, sep='\\t', header=None)\n",
    "\n",
    "mappable_intervals = mappable_intervals[mappable_intervals[0].isin(chroms)]\n",
    "\n",
    "print('chroms:', chroms)\n",
    "print('number_of_intervals:',len(mappable_intervals))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get chrom sizes info\n",
    "chrom_sizes = pd.read_csv(chrom_sizes_path, sep='\\t', header=None)\n",
    "\n",
    "#also keep as a dict\n",
    "chrom_size_dict = chrom_sizes.set_index(0).to_dict()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the ref_seq\n",
    "ref_seq=pysam.FastaFile(ref_seq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the GC content of all fragments where the forward read overlaps the specified regions\n",
    "start_time = time.time()\n",
    "print('Calculating forward read frequency')\n",
    "\n",
    "#create the GC frequencies dict\n",
    "fw_GC_dict = {}\n",
    "for num_GC in range(0,fragment_length+1):\n",
    "    fw_GC_dict[num_GC]=0\n",
    "    \n",
    "for i in range(len(mappable_intervals)):\n",
    "    chrom = mappable_intervals.iloc[i][0]\n",
    "    start = mappable_intervals.iloc[i][1]+1\n",
    "    end = mappable_intervals.iloc[i][2]-1\n",
    "    if i%5000==0:\n",
    "        print('interval',i,':',chrom,start,end,'seconds:',np.round(time.time()-start_time))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    #count up all possible fw reads that overlap the interval\n",
    "    #adjust the start and end so it includes all possible fragment that overlap the interval \n",
    "    adjusted_start = start-read_length\n",
    "    adjusted_end = end+fragment_length\n",
    "    \n",
    "    if adjusted_start<0:\n",
    "        adjusted_start = 0\n",
    "    if adjusted_end>chrom_size_dict[chrom]:\n",
    "        adjusted_end = chrom_sizes_dict[chrom]\n",
    "        print(chrom,chrom_sizes_dict[chrom],'modifying_end_to_end_of_chromosome')\n",
    "    \n",
    "    #count the GC content\n",
    "    fetched = ref_seq.fetch(chrom,adjusted_start,adjusted_end)\n",
    "    fetched = np.array(list(fetched.upper()))\n",
    "    fetched[np.isin(fetched, ['A','T','W'])] = 0\n",
    "    fetched[np.isin(fetched, ['C','G','S'])] = 1\n",
    "    rng = np.random.default_rng(start)\n",
    "    fetched[np.isin(fetched, ['N','R','Y','K','M','B','D','H','V'])] = rng.integers(2, size=len(fetched[np.isin(fetched, ['N','R','Y','K','M','B','D','H','V'])])) #random integer in range(2) (i.e. 0 or 1)\n",
    "    fetched = fetched.astype(float)\n",
    "    \n",
    "    n=len(fetched)\n",
    "    \n",
    "    window_sum = int(sum(fetched[:fragment_length]))\n",
    "    #print(k,len(fetched[:k]),window_sum)\n",
    "\n",
    "    fw_GC_dict[window_sum]+=1\n",
    "    for i in range(n-fragment_length):\n",
    "        window_sum = int(window_sum - fetched[i] + fetched[i+fragment_length])\n",
    "        fw_GC_dict[window_sum]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the GC content of all fragments where the reverse read overlaps the specified regions\n",
    "print('Calculating reverse read frequency')\n",
    "\n",
    "#create the GC frequencies dict\n",
    "rv_GC_dict = {}\n",
    "for num_GC in range(0,fragment_length+1):\n",
    "    rv_GC_dict[num_GC]=0\n",
    "    \n",
    "for i in range(len(mappable_intervals)):\n",
    "    chrom = mappable_intervals.iloc[i][0]\n",
    "    start = mappable_intervals.iloc[i][1]+1 #skip the first and last positions because these reads aren't fetched by pysam\n",
    "    end = mappable_intervals.iloc[i][2]-1\n",
    "    if i%5000==0:\n",
    "        print('interval',i,':',chrom,start,end,'seconds:',np.round(time.time()-start_time))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    #count up all possible rv reads that overlap the interval\n",
    "    #adjust the start and end so it includes all possible fragment that overlap the interval \n",
    "    adjusted_start = start-fragment_length\n",
    "    adjusted_end = end+read_length\n",
    "    \n",
    "    if adjusted_start<0:\n",
    "        adjusted_start = 0\n",
    "    if adjusted_end>chrom_size_dict[chrom]:\n",
    "        adjusted_end = chrom_sizes_dict[chrom]\n",
    "        print(chrom,chrom_sizes_dict[chrom],'modifying_end_to_end_of_chromosome')\n",
    "\n",
    "    #count the GC content\n",
    "    fetched = ref_seq.fetch(chrom,adjusted_start,adjusted_end)\n",
    "    fetched = np.array(list(fetched.upper()))\n",
    "    fetched[np.isin(fetched, ['A','T','W'])] = 0\n",
    "    fetched[np.isin(fetched, ['C','G','S'])] = 1\n",
    "    rng = np.random.default_rng(start)\n",
    "    fetched[np.isin(fetched, ['N','R','Y','K','M','B','D','H','V'])] = rng.integers(2, size=len(fetched[np.isin(fetched, ['N','R','Y','K','M','B','D','H','V'])])) #random integer in range(2) (i.e. 0 or 1)\n",
    "    fetched = fetched.astype(float)\n",
    "    \n",
    "    n=len(fetched)\n",
    "\n",
    "    window_sum = int(sum(fetched[:fragment_length]))\n",
    "    #print(k,len(fetched[:k]),window_sum)\n",
    "\n",
    "    rv_GC_dict[window_sum]+=1\n",
    "    for i in range(n-fragment_length):\n",
    "        window_sum = int(window_sum - fetched[i] + fetched[i+fragment_length])\n",
    "        rv_GC_dict[window_sum]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to df and export\n",
    "GC_df = pd.DataFrame()\n",
    "#save GC dict\n",
    "current = (pd.Series(rv_GC_dict)+pd.Series(fw_GC_dict)).reset_index()\n",
    "current = current.rename(columns={'index':'num_GC',0:'number_of_fragments'})\n",
    "current['length']=fragment_length\n",
    "current = current[['length','num_GC','number_of_fragments']]\n",
    "GC_df = GC_df.append(current, ignore_index=True)\n",
    "GC_df.to_csv(out_file,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
